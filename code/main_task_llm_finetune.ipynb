{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finetuning\n",
    "#### huggingface上にあるLLMをinstallしてきてfinetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jubuntu/anaconda3/envs/unsloth/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338c7de6a6374cda9771658e4ad41d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e0c68719c642f39aaef46a1946de27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '左肺上葉に長径 12cm の腫瘤を認めます。弓部大動脈や肺動脈浸潤が疑われます。\\nT4 と考えます。\\n左肺門や縦隔リンパ節#6 の腫大が見られます。転移が疑われます。N2 と考えます。\\n胸水は認めません。\\n左第 3 肋骨は腫瘤による骨破壊が見られます。他撮像範囲の骨に遠隔転移を疑う所見は指摘できません。\\n撮像範囲の腹部に有意所見は指摘できません。', 'completion': 'T4 N2 M0', 'input_ids': [128000, 30591, 112568, 15682, 104622, 106241, 26854, 103242, 104599, 38641, 1811, 88852, 16144, 83125, 20230, 75146, 109669, 50834, 57942, 118, 23706, 234, 114556, 39926, 40053, 20230, 37656, 102800, 122225, 29295, 125545, 1811, 116748, 27479, 17620, 104770, 15682, 88852, 16144, 30271, 44, 30537, 66115, 41401, 20230, 107253, 26955, 254, 127145, 1811, 99849, 32977, 117952, 101860, 20230, 88852, 30512, 112854, 58942, 5486, 58318, 58942, 109115, 83125, 55031, 114652, 78698, 107290, 30271, 44, 17620, 104770, 30512, 102647, 104127, 72315, 19066, 51, 15, 197, 53229, 102404, 101921, 104, 114431, 235, 30512, 104736, 62004, 100604, 198, 51, 285, 197, 17905, 105871, 32943, 100204, 107106, 104328, 100604, 29295, 25827, 10110, 7063, 18595, 7942, 304, 10109, 123407, 57942, 118, 102212, 25287, 112987, 71289, 29295, 28713, 16144, 126513, 5486, 105843, 103350, 13153, 17620, 67669, 15, 6358, 32149, 59739, 103429, 104721, 37087, 33014, 67669, 111486, 18, 6358, 198, 51, 16, 197, 101921, 104, 114431, 235, 16144, 105843, 103350, 13153, 17620, 67669, 111486, 18, 6358, 5486, 57942, 118, 125845, 26274, 241, 110366, 111140, 115716, 108422, 30297, 27929, 47884, 50834, 107106, 17129, 47884, 20230, 117633, 78183, 115032, 5486, 105065, 95221, 36651, 46456, 101200, 50834, 32149, 25827, 15024, 105755, 16325, 20119, 95, 111363, 27699, 116, 103558, 97, 29295, 95221, 36651, 46456, 117785, 17905, 104736, 62004, 102204, 100604, 10110, 17663, 26854, 78183, 43514, 36668, 95221, 36651, 46456, 20230, 82317, 104127, 16995, 100604, 23954, 51, 16, 8318, 23249, 50034, 83747, 27699, 116, 103558, 97, 34171, 101921, 118, 102802, 109954, 15024, 25827, 100204, 116186, 25827, 72342, 16995, 72342, 25827, 108911, 25827, 5232, 105494, 105843, 103350, 25287, 30512, 20379, 15024, 5486, 105843, 103350, 13153, 17620, 67669, 111486, 15, 13, 20, 6358, 32149, 59739, 103429, 104721, 37087, 33014, 67669, 111486, 18, 6358, 720, 51, 16, 64, 197, 105843, 103350, 13153, 17620, 67669, 111486, 16, 6358, 16556, 32149, 59739, 51, 285, 9458, 51, 16, 8318, 102052, 120019, 21105, 103, 16995, 198, 51, 16, 65, 197, 105843, 103350, 13153, 17620, 67669, 29, 16, 6358, 16556, 32149, 59739, 111486, 17, 6358, 198, 51, 16, 66, 197, 105843, 103350, 13153, 17620, 67669, 29, 17, 6358, 16556, 32149, 59739, 111486, 18, 6358, 198, 51, 17, 197, 105843, 103350, 13153, 17620, 67669, 29, 18, 6358, 16556, 32149, 59739, 111486, 20, 6358, 5486, 125845, 105843, 103350, 13153, 17620, 67669, 111486, 18, 6358, 72661, 88852, 16144, 16995, 101860, 33121, 32149, 103195, 102944, 198, 23249, 23249, 36668, 95221, 36651, 46456, 20230, 82317, 104369, 29295, 95221, 36651, 17620, 58699, 238, 34048, 102052, 82317, 81219, 100604, 198, 23249, 23249, 26274, 241, 110366, 111140, 115716, 20230, 27699, 116, 103558, 97, 198, 23249, 23249, 57942, 118, 103722, 103296, 89046, 106307, 54926, 105494, 9554, 125845, 15120, 110366, 37087, 33014, 16144, 43568, 95221, 57942, 118, 32149, 119962, 59657, 60239, 57942, 118, 114052, 107407, 198, 51, 17, 64, 197, 105843, 103350, 13153, 17620, 67669, 29, 18, 6358, 16556, 32149, 59739, 111486, 19, 6358, 198, 51, 17, 65, 197, 105843, 103350, 13153, 17620, 67669, 29, 19, 6358, 16556, 32149, 59739, 111486, 20, 6358, 198, 51, 18, 197, 105843, 103350, 13153, 17620, 67669, 29, 20, 6358, 16556, 32149, 59739, 111486, 22, 6358, 5486, 125845, 105843, 103350, 13153, 17620, 67669, 111486, 20, 6358, 72661, 88852, 16144, 16995, 101860, 33121, 32149, 103195, 102944, 198, 23249, 23249, 110426, 110366, 111140, 115716, 5486, 111140, 110426, 10110, 9712, 2521, 26858, 57440, 36254, 30512, 96412, 104004, 65459, 109203, 113849, 101365, 106613, 5486, 64209, 115716, 16144, 16995, 101860, 33121, 111201, 109467, 27699, 116, 103558, 97, 198, 23249, 23249, 42016, 15120, 105065, 123727, 16937, 89046, 106307, 26854, 106966, 101921, 104, 114431, 235, 102971, 107792, 198, 51, 19, 197, 105843, 103350, 13153, 17620, 67669, 83354, 22, 6358, 5486, 125845, 119448, 30813, 30512, 99397, 124059, 109203, 113849, 115716, 5486, 102057, 99, 113849, 100204, 116186, 30297, 32149, 47884, 5486, 64209, 26274, 241, 110745, 104473, 36651, 36785, 16995, 76622, 42891, 32149, 25827, 5486, 95221, 36651, 50834, 32149, 25827, 5486, 95543, 18904, 101365, 106613, 15682, 25827, 121867, 15024, 25827, 76622, 16995, 5486, 102456, 45893, 124304, 47884, 104405, 5486, 103433, 236, 33014, 59739, 102334, 16995, 5486, 95221, 36651, 17620, 58699, 238, 34048, 50834, 32149, 25827, 104369, 25827, 50834, 104369, 111363, 27699, 116, 103558, 97, 5486, 101182, 16995, 15682, 42016, 110366, 16144, 108901, 26854, 100472, 57942, 118, 105065, 32943, 112987, 101200, 100604, 16144, 106966, 101921, 104, 114431, 235, 102971, 107792, 1432, 45, 15, 197, 125151, 107805, 80805, 107792, 108436, 60634, 110214, 198, 45, 16, 197, 29295, 25827, 16144, 101182, 57942, 118, 19732, 112361, 110366, 16144, 95221, 36651, 46456, 41642, 116310, 32149, 59739, 14, 125845, 112361, 110366, 16144, 57942, 118, 103722, 5486, 57942, 118, 123727, 107805, 80805, 107792, 111363, 108436, 60634, 107407, 198, 45, 17, 197, 29295, 25827, 16144, 101182, 57942, 118, 19732, 112361, 110366, 16144, 102057, 99, 113849, 32149, 59739, 14, 125845, 95221, 36651, 17620, 58699, 238, 34048, 105755, 17297, 16144, 107805, 80805, 107792, 111363, 108436, 60634, 107407, 198, 45, 18, 197, 29295, 25827, 16144, 101182, 57942, 118, 19732, 95543, 103359, 110366, 16144, 102057, 99, 113849, 5486, 57942, 118, 103722, 112987, 32977, 25827, 5486, 112361, 110366, 101182, 16995, 15682, 95543, 103359, 110366, 16144, 25580, 7741, 250, 64936, 119049, 112371, 25827, 116826, 32149, 47884, 50834, 25827, 10110, 61075, 16144, 119049, 107079, 65459, 109349, 244, 110135, 17905, 91739, 102, 30813, 22957, 59739, 100204, 107106, 32149, 10110, 109349, 244, 110135, 120938, 16144, 47884, 109416, 64121, 120732, 107805, 80805, 107792, 111363, 108436, 60634, 107407, 1432, 44, 15, 197, 110596, 113849, 108436, 60634, 110214, 198, 44, 16, 197, 110596, 113849, 108436, 60634, 107407, 198, 44, 16, 64, 197, 29295, 25827, 16144, 101182, 57942, 118, 19732, 95543, 103359, 110366, 16144, 57942, 118, 123727, 102971, 107792, 5486, 111140, 115716, 125845, 64209, 115716, 16144, 102971, 107792, 5486, 109161, 34171, 111140, 53610, 30591, 47884, 72342, 16995, 50834, 107106, 17663, 16995, 10110, 29295, 25827, 16144, 101182, 57942, 118, 19732, 112361, 110366, 5486, 95543, 103359, 110366, 65459, 109161, 34171, 64209, 115833, 95, 53610, 30591, 47884, 72342, 16995, 15024, 25827, 16144, 30297, 17663, 16995, 29295, 64121, 110071, 198, 44, 16, 65, 197, 57942, 118, 116749, 112028, 26274, 241, 32648, 16995, 43514, 108422, 30297, 50834, 111363, 110904, 102404, 110596, 113849, 108436, 60634, 107407, 198, 44, 16, 66, 197, 57942, 118, 116749, 112028, 26274, 241, 32648, 125845, 43240, 26274, 241, 32648, 28713, 108422, 30297, 50834, 111363, 43240, 102404, 110596, 113849, 108436, 60634, 107407, 1038, 88852, 16144, 83125, 30512, 98499, 104127, 5486, 30271, 44, 17620, 104770, 30512, 37656, 105184, 20230, 121507, 15024, 5486, 59614, 101860, 88852, 16144, 115707, 16556, 20834, 48634, 39926, 72315, 29411, 51, 41082, 31868, 13099, 47217, 60, 452, 41082, 31868, 13099, 47217, 60, 386, 41082, 31868, 13099, 47217, 2595, 78659, 57942, 118, 17905, 105065, 20230, 101544, 67669, 220, 717, 6358, 97718, 101921, 104, 114431, 97, 30512, 104736, 62004, 33541, 1811, 13870, 241, 34048, 27384, 91875, 101171, 230, 71289, 57942, 118, 91875, 101171, 230, 27699, 116, 103558, 97, 29295, 107750, 123671, 33541, 9174, 51, 19, 112031, 113727, 33541, 9174, 78659, 57942, 118, 103722, 71289, 102057, 99, 113849, 107805, 80805, 107792, 2, 21, 97718, 101921, 104, 27384, 29295, 91774, 102204, 33541, 1811, 108436, 60634, 29295, 107750, 123671, 33541, 1811, 45, 17, 112031, 113727, 33541, 9174, 111140, 53610, 15682, 104736, 62004, 107515, 9174, 78659, 30537, 220, 18, 107399, 233, 110135, 15682, 101921, 104, 114431, 97, 111848, 110135, 105150, 127258, 29295, 91774, 102204, 33541, 107751, 125152, 66201, 119318, 116310, 16144, 110135, 20230, 110596, 113849, 108436, 60634, 30512, 107750, 30297, 32938, 91774, 15682, 64467, 112419, 103082, 107515, 9174, 125152, 66201, 119318, 116310, 16144, 113351, 34048, 20230, 19361, 37689, 32938, 91774, 15682, 64467, 112419, 103082, 107515, 1811, 105961, 48634, 5232], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [128000, 51, 19, 452, 17, 386, 15], 'original_inputs': 'あなたは優秀な医師です。以下の文章に基づき肺癌に関して常に正しい判断ができます。進行度分類は以下のTNM第８版に準拠しています。何も言わずに以下を覚え、与えられた文章からよく考えてTNM分類を選んでください。\\n\\n\\n\\nT0\\t原発腫瘍を認めない\\nTis\\t上皮内じょうひないがん（carcinoma in situ）：肺野型はいやがたの場合は、充実成分径0cmかつ病変全体径≦3cm\\nT1\\t腫瘍の充実成分径≦3cm、肺または臓側胸膜ぞうそくきょうまくに覆われている、葉気管支ようきかんしより中枢への浸潤が気管支鏡上認められない（すなわち主気管支に及んでいない）\\nT1mi\\u3000微少浸潤性腺びしょうしんじゅんせいせん がん：部分充実型を示し、充実成分径≦0.5cmかつ病変全体径≦3cm \\nT1a\\t充実成分径≦1cmでかつTis・T1miには相当しない\\nT1b\\t充実成分径>1cmでかつ≦2cm\\nT1c\\t充実成分径>2cmでかつ≦3cm\\nT2\\t充実成分径>3cmでかつ≦5cm、または充実成分径≦3cmでも以下のいずれかであるもの\\n\\u3000\\u3000主気管支に及ぶが気管分岐部には及ばない\\n\\u3000\\u3000臓側胸膜に浸潤\\n\\u3000\\u3000肺門まで連続する部分的または一側全体の無気肺か閉塞性肺炎がある\\nT2a\\t充実成分径>3cmでかつ≦4cm\\nT2b\\t充実成分径>4cmでかつ≦5cm\\nT3\\t充実成分径>5cmでかつ≦7cm、または充実成分径≦5cmでも以下のいずれかであるもの\\n\\u3000\\u3000壁側胸膜、胸壁（superior sulcus tumorを含む）、横隔神経、心膜のいずれかに直接浸潤\\n\\u3000\\u3000同一葉内の不連続な副腫瘍結節\\nT4\\t充実成分径＞7cm、または大きさを問わず横隔膜、縦隔じゅうかく、心臓、大血管だいけっかん、気管きかん、反回神経はんかいしんけい、食道しょくどう、椎体ついたい、気管分岐部きかんぶんきぶへの浸潤、あるいは同側の異なった肺葉内はいようないの副腫瘍結節\\n\\n\\nN0\\t所属リンパ節転移なし\\nN1\\tがんのある肺と同じ側の気管支周囲かつ/または同じ側の肺門、肺内のリンパ節への転移がある\\nN2\\tがんのある肺と同じ側の縦隔かつ/または気管分岐部より下のリンパ節への転移がある\\nN3\\tがんのある肺と反対側の縦隔、肺門はいもん、同じ側あるいは反対側の前斜角筋ぜんしゃかくきん（首の筋肉）、鎖骨上窩さこつじょうか（鎖骨の上のくぼみ）のリンパ節への転移がある\\n\\n\\nM0\\t遠隔転移なし\\nM1\\t遠隔転移がある\\nM1a\\tがんのある肺と反対側の肺内の結節、胸膜または心膜の結節、悪性胸水あくせいきょうすい（がんのある肺と同じ側、反対側）、悪性心嚢水あくせいしんのうすいがみられる\\nM1b\\t肺以外の一臓器いちぞうきへの単発遠隔転移がある\\nM1c\\t肺以外の一臓器または多臓器たぞうきへの多発遠隔転移がある\\n\\n\\n\\n以下の文章を読んで、TNM分類を正確に選択し、必ず以下の形式で出力してください：\\nT<number>[optional_letter] N<number>[optional_letter] M<number>[optional_letter]\\n\\n左肺上葉に長径 12cm の腫瘤を認めます。弓部大動脈や肺動脈浸潤が疑われます。\\nT4 と考えます。\\n左肺門や縦隔リンパ節#6 の腫大が見られます。転移が疑われます。N2 と考えます。\\n胸水は認めません。\\n左第 3 肋骨は腫瘤による骨破壊が見られます。他撮像範囲の骨に遠隔転移を疑う所見は指摘できません。\\n撮像範囲の腹部に有意所見は指摘できません。 出力：', 'original_targets': 'T4 N2 M0', 'text': 'あなたは優秀な医師です。以下の文章に基づき肺癌に関して常に正しい判断ができます。進行度分類は以下のTNM第８版に準拠しています。何も言わずに以下を覚え、与えられた文章からよく考えてTNM分類を選んでください。\\n\\n\\n\\nT0\\t原発腫瘍を認めない\\nTis\\t上皮内じょうひないがん（carcinoma in situ）：肺野型はいやがたの場合は、充実成分径0cmかつ病変全体径≦3cm\\nT1\\t腫瘍の充実成分径≦3cm、肺または臓側胸膜ぞうそくきょうまくに覆われている、葉気管支ようきかんしより中枢への浸潤が気管支鏡上認められない（すなわち主気管支に及んでいない）\\nT1mi\\u3000微少浸潤性腺びしょうしんじゅんせいせん がん：部分充実型を示し、充実成分径≦0.5cmかつ病変全体径≦3cm \\nT1a\\t充実成分径≦1cmでかつTis・T1miには相当しない\\nT1b\\t充実成分径>1cmでかつ≦2cm\\nT1c\\t充実成分径>2cmでかつ≦3cm\\nT2\\t充実成分径>3cmでかつ≦5cm、または充実成分径≦3cmでも以下のいずれかであるもの\\n\\u3000\\u3000主気管支に及ぶが気管分岐部には及ばない\\n\\u3000\\u3000臓側胸膜に浸潤\\n\\u3000\\u3000肺門まで連続する部分的または一側全体の無気肺か閉塞性肺炎がある\\nT2a\\t充実成分径>3cmでかつ≦4cm\\nT2b\\t充実成分径>4cmでかつ≦5cm\\nT3\\t充実成分径>5cmでかつ≦7cm、または充実成分径≦5cmでも以下のいずれかであるもの\\n\\u3000\\u3000壁側胸膜、胸壁（superior sulcus tumorを含む）、横隔神経、心膜のいずれかに直接浸潤\\n\\u3000\\u3000同一葉内の不連続な副腫瘍結節\\nT4\\t充実成分径＞7cm、または大きさを問わず横隔膜、縦隔じゅうかく、心臓、大血管だいけっかん、気管きかん、反回神経はんかいしんけい、食道しょくどう、椎体ついたい、気管分岐部きかんぶんきぶへの浸潤、あるいは同側の異なった肺葉内はいようないの副腫瘍結節\\n\\n\\nN0\\t所属リンパ節転移なし\\nN1\\tがんのある肺と同じ側の気管支周囲かつ/または同じ側の肺門、肺内のリンパ節への転移がある\\nN2\\tがんのある肺と同じ側の縦隔かつ/または気管分岐部より下のリンパ節への転移がある\\nN3\\tがんのある肺と反対側の縦隔、肺門はいもん、同じ側あるいは反対側の前斜角筋ぜんしゃかくきん（首の筋肉）、鎖骨上窩さこつじょうか（鎖骨の上のくぼみ）のリンパ節への転移がある\\n\\n\\nM0\\t遠隔転移なし\\nM1\\t遠隔転移がある\\nM1a\\tがんのある肺と反対側の肺内の結節、胸膜または心膜の結節、悪性胸水あくせいきょうすい（がんのある肺と同じ側、反対側）、悪性心嚢水あくせいしんのうすいがみられる\\nM1b\\t肺以外の一臓器いちぞうきへの単発遠隔転移がある\\nM1c\\t肺以外の一臓器または多臓器たぞうきへの多発遠隔転移がある\\n\\n\\n\\n以下の文章を読んで、TNM分類を正確に選択し、必ず以下の形式で出力してください：\\nT<number>[optional_letter] N<number>[optional_letter] M<number>[optional_letter]\\n\\n左肺上葉に長径 12cm の腫瘤を認めます。弓部大動脈や肺動脈浸潤が疑われます。\\nT4 と考えます。\\n左肺門や縦隔リンパ節#6 の腫大が見られます。転移が疑われます。N2 と考えます。\\n胸水は認めません。\\n左第 3 肋骨は腫瘤による骨破壊が見られます。他撮像範囲の骨に遠隔転移を疑う所見は指摘できません。\\n撮像範囲の腹部に有意所見は指摘できません。 出力：'}\n"
     ]
    }
   ],
   "source": [
    "## データセットの準備\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from accelerate import Accelerator\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# GPUの確認\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# モデルとトークナイザーのロード\n",
    "model_name = \"pfnet/Llama3-Preferred-MedSwallow-70B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def prepare_dataset(jsonl_file_path):\n",
    "    data = []\n",
    "    with open(jsonl_file_path, 'r', encoding='utf-8') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            entry = json.loads(line.strip())\n",
    "            data.append({\n",
    "                \"prompt\": entry[\"prompt\"],\n",
    "                \"completion\": entry[\"completion\"]\n",
    "            })\n",
    "    return Dataset.from_list(data)\n",
    "\n",
    "# データセットのロード\n",
    "jsonl_file_path_train = \"../finetune_jsons/finetune_dataset_train.jsonl\"\n",
    "dataset_train = prepare_dataset(jsonl_file_path_train)\n",
    "jsonl_file_path_val = \"../finetune_jsons/finetune_dataset_val.jsonl\"\n",
    "dataset_val = prepare_dataset(jsonl_file_path_val)\n",
    "\n",
    "with open('../tnm_prompt.txt', 'r', encoding='utf-8') as file:\n",
    "    tnm_prompt_text = file.read()\n",
    "\n",
    "tnm_prompt_text_base = (\n",
    "    \"あなたは優秀な医師です。以下の文章に基づき肺癌に関して常に正しい判断ができます。\"\n",
    "    \"進行度分類は以下のTNM第８版に準拠しています。何も言わずに以下を覚え、与えられた文章からよく考えてTNM分類を選んでください。\\n\\n\"\n",
    ")\n",
    "tnm_prompt = (\n",
    "    f\"{tnm_prompt_text_base}\\n\\n\"\n",
    "    f\"{tnm_prompt_text}\\n\\n\"\n",
    "    \"以下の文章を読んで、TNM分類を正確に選択し、必ず以下の形式で出力してください：\\n\"\n",
    "    \"T<number>[optional_letter] N<number>[optional_letter] M<number>[optional_letter]\\n\\n\"\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    \n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [f\"{tnm_prompt}{prompt} 出力：\" for prompt in examples['prompt']]\n",
    "    targets = [completion for completion in examples['completion']]\n",
    "    \n",
    "    # トークナイズ (入力)\n",
    "    model_inputs = tokenizer(inputs, truncation=True, padding=False)\n",
    "    \n",
    "    # トークナイズ (ラベル)\n",
    "    labels = tokenizer(targets, truncation=True, padding=False)\n",
    "    \n",
    "    # -100 をラベルのパディングに設定\n",
    "    labels[\"input_ids\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in label]\n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    # 元のテキストも保持\n",
    "    model_inputs[\"original_inputs\"] = inputs\n",
    "    model_inputs[\"original_targets\"] = targets\n",
    "    model_inputs[\"text\"] = inputs\n",
    "    \n",
    "    return model_inputs\n",
    "\n",
    "# 元のテキストを保持しつつデータセットを生成\n",
    "train_dataset = dataset_train.map(preprocess_function, batched=True)\n",
    "eval_dataset = dataset_val.map(preprocess_function, batched=True)\n",
    "\n",
    "\n",
    "\n",
    "##sample output\n",
    "print(train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inferenceのコード\n",
    "\n",
    "# 推論関数の定義\n",
    "def inference(dataset, model, tokenizer, max_length=2048):\n",
    "    results = []\n",
    "    for data in tqdm(dataset):\n",
    "        # 入力テキストを取得\n",
    "        input_text = data[\"original_inputs\"]\n",
    "        \n",
    "        # トークナイズ (モデルが理解できる形式に変換)\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=max_length).to(model.device)\n",
    "        \n",
    "        # モデルの推論\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_length=max_length,  # 最大出力長\n",
    "                early_stopping=True,  # 早期終了を有効化\n",
    "                eos_token_id=tokenizer.eos_token_id,  # EOSトークンを設定\n",
    "                do_sample=True,  # サンプリングを有効化\n",
    "                top_k=50,  # 上位kトークンから選択\n",
    "                top_p=0.95  # トークンの確率質量\n",
    "            )\n",
    "\n",
    "        \n",
    "        # デコード (トークン列をテキストに変換)\n",
    "        output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # 結果を保存\n",
    "        results.append({\n",
    "            \"input\": input_text,\n",
    "            \"generated_output\": output_text,\n",
    "            \"expected_output\": data[\"original_targets\"]\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: BNB_CUDA_VERSION=121 environment variable detected; loading libbitsandbytes_cuda121.so.\n",
      "This can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH\n",
      "For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2024.11.10: Fast Llama patching. Transformers:4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.425 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1. CUDA: 8.6. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56a9ecc68234fe5ad305a75575c501b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0475159fae4696b1a34b4f5ba4f7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pfnet/Llama3-Preferred-MedSwallow-70B does not have a padding token! Will use pad_token = <|reserved_special_token_250|>.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel \n",
    "from unsloth import is_bfloat16_supported\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from datasets import load_dataset\n",
    "max_seq_length = 2048 # Supports RoPE Scaling interally, so choose any!\n",
    "# Get LAION dataset\n",
    "# url = \"https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl\"\n",
    "# dataset = load_dataset(\"json\", data_files = {\"train\" : url}, split = \"train\")\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## finetune前の確認\n",
    "\n",
    "# 推論実行\n",
    "inference_results = inference(eval_dataset[:3], model, tokenizer)\n",
    "\n",
    "# 結果を表示\n",
    "for i, result in enumerate(inference_results):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Input: {result['input']}\")\n",
    "    print(f\"Generated Output: {result['generated_output']}\")\n",
    "    print(f\"Expected Output: {result['expected_output']}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.11.10 patched 80 layers with 80 QKV layers, 80 O layers and 80 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    label_pad_token_id=-100,\n",
    "    padding=True,  # 動的パディングを有効にする\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = data_collator,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part=\"あなたは優秀な医師です。以下の文章に基づき肺癌に関して常に正しい判断ができます。\",  # インストラクション部分を指定\n",
    "    response_part=\"出力：\"  # レスポンス部分を指定\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 108 | Num Epochs = 5\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 60\n",
      " \"-____-\"     Number of trainable parameters = 207,093,760\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdac6631b3e0416fbf989ad17e9ee4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8381, 'grad_norm': 0.4072749614715576, 'learning_rate': 4e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7384, 'grad_norm': 0.36444002389907837, 'learning_rate': 8e-05, 'epoch': 0.15}\n",
      "{'loss': 1.7724, 'grad_norm': 0.3491908013820648, 'learning_rate': 0.00012, 'epoch': 0.22}\n",
      "{'loss': 1.7671, 'grad_norm': 0.5786504745483398, 'learning_rate': 0.00016, 'epoch': 0.3}\n",
      "{'loss': 1.6427, 'grad_norm': 0.4702806770801544, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
      "{'loss': 1.5077, 'grad_norm': 0.48127204179763794, 'learning_rate': 0.00019636363636363636, 'epoch': 0.44}\n",
      "{'loss': 1.3497, 'grad_norm': 0.6133865714073181, 'learning_rate': 0.00019272727272727274, 'epoch': 0.52}\n",
      "{'loss': 1.349, 'grad_norm': 3.6691014766693115, 'learning_rate': 0.0001890909090909091, 'epoch': 0.59}\n",
      "{'loss': 1.1671, 'grad_norm': 0.5333468914031982, 'learning_rate': 0.00018545454545454545, 'epoch': 0.67}\n",
      "{'loss': 1.1274, 'grad_norm': 0.4787834882736206, 'learning_rate': 0.00018181818181818183, 'epoch': 0.74}\n",
      "{'loss': 1.1379, 'grad_norm': 0.4744940996170044, 'learning_rate': 0.0001781818181818182, 'epoch': 0.81}\n",
      "{'loss': 1.0749, 'grad_norm': 0.43891769647598267, 'learning_rate': 0.00017454545454545454, 'epoch': 0.89}\n",
      "{'loss': 1.0666, 'grad_norm': 0.45089587569236755, 'learning_rate': 0.0001709090909090909, 'epoch': 0.96}\n",
      "{'loss': 1.5115, 'grad_norm': 0.7233561873435974, 'learning_rate': 0.00016727272727272728, 'epoch': 1.04}\n",
      "{'loss': 0.9219, 'grad_norm': 0.38212257623672485, 'learning_rate': 0.00016363636363636366, 'epoch': 1.11}\n",
      "{'loss': 0.9122, 'grad_norm': 0.4429636597633362, 'learning_rate': 0.00016, 'epoch': 1.19}\n",
      "{'loss': 0.7687, 'grad_norm': 0.37760111689567566, 'learning_rate': 0.00015636363636363637, 'epoch': 1.26}\n",
      "{'loss': 0.9016, 'grad_norm': 0.38100793957710266, 'learning_rate': 0.00015272727272727275, 'epoch': 1.33}\n",
      "{'loss': 1.042, 'grad_norm': 0.4578867554664612, 'learning_rate': 0.0001490909090909091, 'epoch': 1.41}\n",
      "{'loss': 0.6612, 'grad_norm': 0.37774598598480225, 'learning_rate': 0.00014545454545454546, 'epoch': 1.48}\n",
      "{'loss': 0.9471, 'grad_norm': 0.44463348388671875, 'learning_rate': 0.00014181818181818184, 'epoch': 1.56}\n",
      "{'loss': 0.8164, 'grad_norm': 0.4159707725048065, 'learning_rate': 0.0001381818181818182, 'epoch': 1.63}\n",
      "{'loss': 0.941, 'grad_norm': 0.4307209849357605, 'learning_rate': 0.00013454545454545455, 'epoch': 1.7}\n",
      "{'loss': 0.7133, 'grad_norm': 0.38697025179862976, 'learning_rate': 0.00013090909090909093, 'epoch': 1.78}\n",
      "{'loss': 0.89, 'grad_norm': 0.40672358870506287, 'learning_rate': 0.00012727272727272728, 'epoch': 1.85}\n",
      "{'loss': 0.8776, 'grad_norm': 0.40502941608428955, 'learning_rate': 0.00012363636363636364, 'epoch': 1.93}\n",
      "{'loss': 1.2088, 'grad_norm': 0.5576397776603699, 'learning_rate': 0.00012, 'epoch': 2.0}\n",
      "{'loss': 0.6984, 'grad_norm': 0.4023154079914093, 'learning_rate': 0.00011636363636363636, 'epoch': 2.07}\n",
      "{'loss': 0.8098, 'grad_norm': 0.3994697332382202, 'learning_rate': 0.00011272727272727272, 'epoch': 2.15}\n",
      "{'loss': 0.6024, 'grad_norm': 0.39395031332969666, 'learning_rate': 0.00010909090909090909, 'epoch': 2.22}\n",
      "{'loss': 0.6845, 'grad_norm': 0.44504621624946594, 'learning_rate': 0.00010545454545454545, 'epoch': 2.3}\n",
      "{'loss': 0.6537, 'grad_norm': 0.4104446768760681, 'learning_rate': 0.00010181818181818181, 'epoch': 2.37}\n",
      "{'loss': 0.6738, 'grad_norm': 0.45404812693595886, 'learning_rate': 9.818181818181818e-05, 'epoch': 2.44}\n",
      "{'loss': 0.6134, 'grad_norm': 0.4455665946006775, 'learning_rate': 9.454545454545455e-05, 'epoch': 2.52}\n",
      "{'loss': 0.5681, 'grad_norm': 0.5403136014938354, 'learning_rate': 9.090909090909092e-05, 'epoch': 2.59}\n",
      "{'loss': 0.6857, 'grad_norm': 0.5693321228027344, 'learning_rate': 8.727272727272727e-05, 'epoch': 2.67}\n",
      "{'loss': 0.6993, 'grad_norm': 0.5823256969451904, 'learning_rate': 8.363636363636364e-05, 'epoch': 2.74}\n",
      "{'loss': 0.6455, 'grad_norm': 0.6148393154144287, 'learning_rate': 8e-05, 'epoch': 2.81}\n",
      "{'loss': 0.5755, 'grad_norm': 0.49833372235298157, 'learning_rate': 7.636363636363637e-05, 'epoch': 2.89}\n",
      "{'loss': 0.6437, 'grad_norm': 0.47686371207237244, 'learning_rate': 7.272727272727273e-05, 'epoch': 2.96}\n",
      "{'loss': 0.8716, 'grad_norm': 0.7296509146690369, 'learning_rate': 6.90909090909091e-05, 'epoch': 3.04}\n",
      "{'loss': 0.517, 'grad_norm': 0.4170914888381958, 'learning_rate': 6.545454545454546e-05, 'epoch': 3.11}\n",
      "{'loss': 0.6783, 'grad_norm': 0.5008776187896729, 'learning_rate': 6.181818181818182e-05, 'epoch': 3.19}\n",
      "{'loss': 0.4893, 'grad_norm': 0.5498774647712708, 'learning_rate': 5.818181818181818e-05, 'epoch': 3.26}\n",
      "{'loss': 0.4206, 'grad_norm': 0.46303197741508484, 'learning_rate': 5.4545454545454546e-05, 'epoch': 3.33}\n",
      "{'loss': 0.4863, 'grad_norm': 0.49719223380088806, 'learning_rate': 5.090909090909091e-05, 'epoch': 3.41}\n",
      "{'loss': 0.5056, 'grad_norm': 0.6029546856880188, 'learning_rate': 4.7272727272727275e-05, 'epoch': 3.48}\n",
      "{'loss': 0.389, 'grad_norm': 0.5620816946029663, 'learning_rate': 4.3636363636363636e-05, 'epoch': 3.56}\n",
      "{'loss': 0.5438, 'grad_norm': 0.8492675423622131, 'learning_rate': 4e-05, 'epoch': 3.63}\n",
      "{'loss': 0.5325, 'grad_norm': 0.8468216061592102, 'learning_rate': 3.6363636363636364e-05, 'epoch': 3.7}\n",
      "{'loss': 0.4851, 'grad_norm': 0.7540938854217529, 'learning_rate': 3.272727272727273e-05, 'epoch': 3.78}\n",
      "{'loss': 0.5088, 'grad_norm': 0.6943033337593079, 'learning_rate': 2.909090909090909e-05, 'epoch': 3.85}\n",
      "{'loss': 0.4536, 'grad_norm': 0.6293154954910278, 'learning_rate': 2.5454545454545454e-05, 'epoch': 3.93}\n",
      "{'loss': 0.7124, 'grad_norm': 1.1205803155899048, 'learning_rate': 2.1818181818181818e-05, 'epoch': 4.0}\n",
      "{'loss': 0.4184, 'grad_norm': 0.572246253490448, 'learning_rate': 1.8181818181818182e-05, 'epoch': 4.07}\n",
      "{'loss': 0.4148, 'grad_norm': 0.5867884755134583, 'learning_rate': 1.4545454545454545e-05, 'epoch': 4.15}\n",
      "{'loss': 0.3857, 'grad_norm': 0.6003087162971497, 'learning_rate': 1.0909090909090909e-05, 'epoch': 4.22}\n",
      "{'loss': 0.3693, 'grad_norm': 0.5988588929176331, 'learning_rate': 7.272727272727272e-06, 'epoch': 4.3}\n",
      "{'loss': 0.4228, 'grad_norm': 0.6816331744194031, 'learning_rate': 3.636363636363636e-06, 'epoch': 4.37}\n",
      "{'loss': 0.452, 'grad_norm': 0.6094508171081543, 'learning_rate': 0.0, 'epoch': 4.44}\n",
      "{'train_runtime': 3146.3974, 'train_samples_per_second': 0.153, 'train_steps_per_second': 0.019, 'train_loss': 0.8377200906475385, 'epoch': 4.44}\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "# モデルとトークナイザーのロード\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# モデルの推論モード設定\n",
    "model = FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 推論実行\n",
    "inference_results = inference(eval_dataset, model, tokenizer)\n",
    "\n",
    "# 結果を表示\n",
    "for i, result in enumerate(inference_results):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Input: {result['input']}\")\n",
    "    print(f\"Generated Output: {result['generated_output']}\")\n",
    "    print(f\"Expected Output: {result['expected_output']}\")\n",
    "    print(\"----\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
