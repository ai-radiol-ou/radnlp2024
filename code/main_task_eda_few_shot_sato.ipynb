{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1c N0 M0\n"
     ]
    }
   ],
   "source": [
    "import re  # 正規表現ライブラリをインポート\n",
    "\n",
    "def validate_and_correct_tnm_output(tnm_stage):\n",
    "    \"\"\"\n",
    "    TNM分類の形式を検証し、不正な形式の場合は修正する。\n",
    "    \"\"\"\n",
    "    # 正規表現でTNM分類をチェック\n",
    "    tnm_pattern = (\n",
    "        r\"T(?:0|is|1mi|1[abc]?|2[ab]?|3|4) \"  # Tの分類\n",
    "        r\"N(?:0|1|2|3) \"                     # Nの分類\n",
    "        r\"M(?:0|1[abc]?)\"                    # Mの分類\n",
    "    )\n",
    "    if re.fullmatch(tnm_pattern, tnm_stage):\n",
    "        # 正しい形式の場合、そのまま返す\n",
    "        return tnm_stage\n",
    "    else:\n",
    "        # 正規表現パターンに一致する部分を検索\n",
    "        match = re.search(tnm_pattern, tnm_stage)\n",
    "        if match:\n",
    "            return match.group()  # 一致する部分文字列を返す\n",
    "        else:\n",
    "            return None  # 一致する部分がない場合はNoneを返す\n",
    "\n",
    "tmp = 'output: T1c N0 M0'\n",
    "print(validate_and_correct_tnm_output(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'文章': '左上葉全体が無気肺になっています。\\n左上葉気管支は閉塞して造影  CT  で増強効果の乏しい 74mm  の腫瘤があります。\\n肺癌と考えます。\\n左肺門、同側縦隔リンパ節腫大しリンパ節転移と考えます。\\n気管右側にもリンパ節腫大があり、こちらもリンパ節転移を疑います。\\n左下葉気管支も腫瘍により浸潤あり、狭窄しています。\\n胸水貯留は認めません。\\n撮影範囲の腹部臓器に粗大な異常を認めません。',\n",
       "  '出力': 'T4 N3 M0'},\n",
       " {'文章': '右下葉 S8 に⻑径 30mm の腫瘤性病変があります。辺縁には spicula を伴っています。肺癌の可能性がありますので、呼吸器科的に精査ください。\\n左下葉には炎症瘢痕様の索状影を認めます。\\n右肺門リンパ節腫大が疑われます。胸水認めません。',\n",
       "  '出力': 'T1c N0 M0'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_label_path = '../radnlp_2024_train_val_20240731/ja/main_task/train/label.csv'\n",
    "df_train_label = pd.read_csv(train_label_path)\n",
    "\n",
    "few_shot_examples = []\n",
    "\n",
    "def example(row):\n",
    "    ex_dict = {}\n",
    "    study_id = row[\"id\"]\n",
    "    t = row[\"t\"]\n",
    "    n = row[\"n\"]\n",
    "    m = row[\"m\"]\n",
    "    txt_path = f'../radnlp_2024_train_val_20240731/ja/main_task/train/{study_id}.txt'\n",
    "    with open(txt_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    ex_dict[\"文章\"] = content\n",
    "    ex_dict[\"出力\"] = f\"{t} {n} {m}\"\n",
    "    few_shot_examples.append(ex_dict)\n",
    "\n",
    "df_train_label.apply(example, axis=1)\n",
    "\n",
    "#display(df_train_label.head())\n",
    "few_shot_examples[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル o1-preview-2024-09-12 を使用してTNM分類を予測中...\n",
      "number of text files: 54\n",
      "結果が../fewshot_submission_o1-preview-2024-09-12.csvに保存されました！\n",
      "CPU times: user 1.13 s, sys: 52.8 ms, total: 1.18 s\n",
      "Wall time: 41min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain.callbacks import tracing_enabled\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "from langsmith import Client, traceable\n",
    "\n",
    "import datetime\n",
    "import pytz\n",
    "now = str(datetime.datetime.now(pytz.timezone('Asia/Tokyo')))[:-16]; now = now.replace(\" \", \"_\").replace(\"-\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "load_dotenv()\n",
    "ANTHROPIC_API_KEY  = os.getenv('ANTHROPIC_API_KEY')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# OpenAIのAPIキーを環境変数から取得\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"{now}_radnlp2024\"\n",
    "model_names = ['o1-preview-2024-09-12']  # ['gpt-4o-2024-05-13','gpt-4o-mini-2024-07-18','o1-preview-2024-09-12']\n",
    "#model_names = [\"claude-3-sonnet-20240229\"]\n",
    "\n",
    "# プロンプトテンプレートの読み込み\n",
    "with open('../tnm_prompt.txt', 'r', encoding='utf-8') as file:\n",
    "    tnm_prompt_text = file.read()\n",
    "\n",
    "# FewShotPromptTemplateを作成\n",
    "examples = [{\"content\": ex[\"文章\"], \"tnm\": ex[\"出力\"]} for ex in few_shot_examples]\n",
    "\n",
    "example_template = \"\"\"\n",
    "文章: {content}\n",
    "出力: {tnm}\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=PromptTemplate(\n",
    "        input_variables=[\"content\", \"tnm\"],\n",
    "        template=example_template\n",
    "    ),\n",
    "    prefix=(\n",
    "        \"あなたは優秀な医師です。以下の文章に基づき肺癌に関して常に正しい判断ができます。\"\n",
    "        \"進行度分類は以下のTNM第８版に準拠しています。何も言わずに以下を覚え、与えられた文章からよく考えてTNM分類を選んでください。\\n\\n\"\n",
    "        f\"{tnm_prompt_text}\"\n",
    "    ),\n",
    "    suffix=(\n",
    "        \"以下の文章を読んで、TNM分類を正確に選択し、必ず以下の形式で出力してください：\\n\"\n",
    "        \"T<number>[optional_letter] N<number>[optional_letter] M<number>[optional_letter]\\n\\n\"\n",
    "        \"{content}\\n\\n\"\n",
    "        \"出力：\"\n",
    "    ),\n",
    "    input_variables=[\"content\"]\n",
    ")\n",
    "# モデルごとに処理\n",
    "for model_name in model_names:\n",
    "    print(f\"モデル {model_name} を使用してTNM分類を予測中...\")\n",
    "    output_csv = f'../fewshot_submission_{model_name}.csv'\n",
    "\n",
    "    if \"claude\" in model_name:\n",
    "        llm = ChatAnthropic(\n",
    "            model=model_name,\n",
    "            temperature=0,\n",
    "        )\n",
    "    # LLMの設定（ChatGPTを使用）\n",
    "    elif '4o' in model_name:\n",
    "        llm = ChatOpenAI(temperature=0.7,model_name=model_name)\n",
    "    else:\n",
    "        llm = ChatOpenAI(temperature=1,model_name=model_name)\n",
    "\n",
    "    # チェーンの作成\n",
    "    chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
    "\n",
    "    # テスト用の入力\n",
    "    txt_folder = '../radnlp_2024_train_val_20240731/ja/main_task/val/'  # ここをTXTファイルが保存されているフォルダに変更\n",
    "    txt_files = [f for f in os.listdir(txt_folder) if f.endswith('.txt')]\n",
    "    print('number of text files:', len(txt_files))\n",
    "\n",
    "    results = []\n",
    "    for file_name in sorted(txt_files):\n",
    "        file_path = os.path.join(txt_folder, file_name)\n",
    "        # ファイルを読み込む\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        try:\n",
    "            tnm_stage = chain.run({\"content\": content}).strip()\n",
    "\n",
    "            # TNM分類の形式を検証・修正（この部分はユーザーのvalidate_and_correct_tnm_output関数を流用）\n",
    "            tnm_stage = validate_and_correct_tnm_output(tnm_stage)\n",
    "\n",
    "            # TNM分類を分割\n",
    "            tnm_parts = tnm_stage.split()\n",
    "            if len(tnm_parts) >= 3:\n",
    "                results.append({\n",
    "                    \"id\": file_name.split('.')[0],\n",
    "                    \"t\": tnm_parts[0],\n",
    "                    \"n\": tnm_parts[1],\n",
    "                    \"m\": tnm_parts[2],\n",
    "                })\n",
    "            else:\n",
    "                print(f\"ファイル {file_name} のTNM分類の出力形式が正しくありません: {tnm_stage}\")\n",
    "        except Exception as e:\n",
    "            print(f\"エラーが発生しました: {file_name} - {e}\")\n",
    "            continue\n",
    "\n",
    "    # DataFrameに変換してCSVファイルに保存\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"結果が{output_csv}に保存されました！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# モデルとトークナイザーのロード\n",
    "model_name = \"bigscience/bloomz-7b1\"  # Hugging Faceモデル名を指定\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# テストデータのディレクトリ\n",
    "txt_folder = '../radnlp_2024_train_val_20240731/ja/main_task/val/'\n",
    "txt_files = [f for f in os.listdir(txt_folder) if f.endswith('.txt')]\n",
    "print('number of text files:', len(txt_files))\n",
    "\n",
    "# Few-shot例を定義\n",
    "examples = [\n",
    "    {\"content\": \"対象文1\", \"tnm\": \"T1a N0 M0\"},\n",
    "    {\"content\": \"対象文2\", \"tnm\": \"T2b N1 M0\"},\n",
    "]\n",
    "\n",
    "# Few-shotプロンプトを構築\n",
    "def construct_few_shot_prompt(examples, tnm_prompt_text):\n",
    "    \"\"\"\n",
    "    Few-shot学習用のプロンプトを生成。\n",
    "    \"\"\"\n",
    "    example_template = \"\"\"\n",
    "文章: {content}\n",
    "出力: {tnm}\n",
    "\"\"\"\n",
    "    few_shot_examples = \"\\n\".join(\n",
    "        example_template.format(content=ex[\"content\"], tnm=ex[\"tnm\"]) for ex in examples\n",
    "    )\n",
    "    \n",
    "    prompt_template = f\"\"\"\n",
    "あなたは優秀な医師です。以下の文章に基づき肺癌に関して常に正しい判断ができます。\n",
    "進行度分類は以下のTNM第８版に準拠しています。何も言わずに以下を覚え、与えられた文章からよく考えてTNM分類を選んでください。\n",
    "\n",
    "{tnm_prompt_text}\n",
    "\n",
    "Few-shot Examples:\n",
    "{few_shot_examples}\n",
    "\n",
    "以下の文章を読んで、TNM分類を正確に選択し、必ず以下の形式で出力してください：\n",
    "T<number>[optional_letter] N<number>[optional_letter] M<number>[optional_letter]\n",
    "\n",
    "文章:\n",
    "\"\"\"\n",
    "    return prompt_template\n",
    "\n",
    "# tnm_prompt.txtを読み込み\n",
    "with open('../tnm_prompt.txt', 'r', encoding='utf-8') as file:\n",
    "    tnm_prompt_text = file.read()\n",
    "\n",
    "# Few-shotプロンプトを生成\n",
    "prompt_template = construct_few_shot_prompt(examples, tnm_prompt_text)\n",
    "\n",
    "results = []\n",
    "\n",
    "# 各テキストファイルを処理\n",
    "for file_name in sorted(txt_files):\n",
    "    file_path = os.path.join(txt_folder, file_name)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # プロンプトを作成\n",
    "    prompt = f\"{prompt_template}{content}\\n\\n出力：\"\n",
    "    \n",
    "    # モデル推論の実行\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    outputs = model.generate(**inputs, max_length=128)\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    \n",
    "    try:\n",
    "        # 出力を分割し、TNM分類を抽出\n",
    "        tnm_parts = output_text.split()\n",
    "        if len(tnm_parts) >= 3:\n",
    "            results.append({\n",
    "                \"id\": file_name.split('.')[0],\n",
    "                \"t\": tnm_parts[0],\n",
    "                \"n\": tnm_parts[1],\n",
    "                \"m\": tnm_parts[2],\n",
    "            })\n",
    "        else:\n",
    "            print(f\"ファイル {file_name} の出力形式が正しくありません: {output_text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"エラーが発生しました: {file_name} - {e}\")\n",
    "        continue\n",
    "\n",
    "# DataFrameに変換してCSVファイルに保存\n",
    "results_df = pd.DataFrame(results)\n",
    "output_csv = '../huggingface_tnm_classification_results.csv'\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"結果が{output_csv}に保存されました！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
